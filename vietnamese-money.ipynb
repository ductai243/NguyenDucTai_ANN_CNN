{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Libraries\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nimport os\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import layers\n# Gọi các thư viện cần thiết \nimport pandas as pd # Xu lý bảng\nimport seaborn as sns # Vẽ biểu đồ thị của dữ liệu\nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import StandardScaler # Xử lý chuẩn hóa dữ liệu\nfrom sklearn.model_selection import train_test_split # Chia dữ liệu ra làm 2 phần\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization, LSTM    # LSTM  biên dạng ANN, BatchNormalization: cho nhỏ lại\nfrom keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical # Sử dung để làm nổi đối tượng cần phân loại\nfrom keras import callbacks \nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score # Để đo lường\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nfrom tensorflow.keras.preprocessing import image\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom keras import callbacks\nimport keras\nfrom keras.layers import Dense # fully connected\nfrom keras.datasets import boston_housing\nfrom tensorflow.keras.optimizers import RMSprop # toi uu\nfrom keras.callbacks import EarlyStopping # dung lai ngay lap tuc\nfrom sklearn.preprocessing import scale # xu li du lieu\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-20T06:19:49.516651Z","iopub.execute_input":"2022-05-20T06:19:49.517057Z","iopub.status.idle":"2022-05-20T06:19:49.530165Z","shell.execute_reply.started":"2022-05-20T06:19:49.517022Z","shell.execute_reply":"2022-05-20T06:19:49.529446Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Load 1 image\nimg = image.load_img(\"../input/11-money/10000/1.jpg\")\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:09:01.310660Z","iopub.execute_input":"2022-05-20T06:09:01.310912Z","iopub.status.idle":"2022-05-20T06:09:01.550542Z","shell.execute_reply.started":"2022-05-20T06:09:01.310885Z","shell.execute_reply":"2022-05-20T06:09:01.549649Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Reshape data\nimport glob\nm200 = glob.glob('../input/11-money/200/*.*')\nm500 = glob.glob('../input/11-money/500/*.*')\nm1000 = glob.glob('../input/11-money/1000/*.*')\nm2000 = glob.glob('../input/11-money/2000/*.*')\nm5000 = glob.glob('../input/11-money/5000/*.*')\nm10000 = glob.glob('../input/11-money/10000/*.*')\nm20000 = glob.glob('../input/11-money/20000/*.*')\nm50000 = glob.glob('../input/11-money/50000/*.*')\nm100000 = glob.glob('../input/11-money/100000/*.*')\nm200000 = glob.glob('../input/11-money/200000/*.*')\nm500000 = glob.glob('../input/11-money/500000/*.*')\n\n\ndata = []\nlabels = []\n\nfor i in m200:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(0)\nfor i in m500:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(1)\nfor i in m1000:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(2)\nfor i in m2000:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(3)\n\nfor i in m5000:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(4)\nfor i in m10000:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(5)\nfor i in m20000:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(6)\nfor i in m50000:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(7)\nfor i in m100000:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(8)\nfor i in m200000:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(9)\nfor i in m500000:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(10)\n\ndata = np.array(data)\nlabels = np.array(labels)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.2,\n                                                random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:09:03.924584Z","iopub.execute_input":"2022-05-20T06:09:03.925201Z","iopub.status.idle":"2022-05-20T06:09:06.557857Z","shell.execute_reply.started":"2022-05-20T06:09:03.925166Z","shell.execute_reply":"2022-05-20T06:09:06.557140Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape,Y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:09:11.756393Z","iopub.execute_input":"2022-05-20T06:09:11.756653Z","iopub.status.idle":"2022-05-20T06:09:11.761336Z","shell.execute_reply.started":"2022-05-20T06:09:11.756625Z","shell.execute_reply":"2022-05-20T06:09:11.760614Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reshape((X_train.shape[0],150,150,3)).astype('float32')/255\nX_test = X_test.reshape((X_test.shape[0],150,150,3)).astype('float32')/255\n\nY_train = to_categorical(Y_train,11)\nY_test = to_categorical(Y_test,11)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:09:13.902681Z","iopub.execute_input":"2022-05-20T06:09:13.902935Z","iopub.status.idle":"2022-05-20T06:09:13.932774Z","shell.execute_reply.started":"2022-05-20T06:09:13.902907Z","shell.execute_reply":"2022-05-20T06:09:13.931983Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:09:16.140108Z","iopub.execute_input":"2022-05-20T06:09:16.140925Z","iopub.status.idle":"2022-05-20T06:09:16.154252Z","shell.execute_reply.started":"2022-05-20T06:09:16.140812Z","shell.execute_reply":"2022-05-20T06:09:16.153161Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Create model\nfrom keras.layers import Conv2D, MaxPooling2D\nmodel = Sequential()\nmodel.add(Conv2D(32,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(150,150,3)))\nmodel.add(Conv2D(32,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same'))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(64,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same')) # 64 lan tich chap\nmodel.add(Conv2D(64,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same'))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(128,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same')) # 128 lan tich chap\nmodel.add(Conv2D(128,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same'))\nmodel.add(MaxPooling2D(2,2))\n\n# model.add(Conv2D(256,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same')) # 256 lan tich chap\n# model.add(Conv2D(256,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same'))\n# model.add(MaxPooling2D(2,2))\n\n\nfrom keras.layers import Dense, Activation, Flatten\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(11))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:09:23.691435Z","iopub.execute_input":"2022-05-20T06:09:23.691699Z","iopub.status.idle":"2022-05-20T06:09:23.779883Z","shell.execute_reply.started":"2022-05-20T06:09:23.691671Z","shell.execute_reply":"2022-05-20T06:09:23.779201Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Training\nmodel.compile(loss='mse',optimizer=RMSprop(),metrics=['accuracy'])\nhistory = model.fit(X_train, Y_train, epochs =200, batch_size =128,validation_data=(X_test,Y_test) , verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:09:28.390699Z","iopub.execute_input":"2022-05-20T06:09:28.390967Z","iopub.status.idle":"2022-05-20T06:10:51.289180Z","shell.execute_reply.started":"2022-05-20T06:09:28.390939Z","shell.execute_reply":"2022-05-20T06:10:51.288403Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Save model\nfrom tensorflow.keras.models import load_model\nmodel.save('Final.h5')\nmodel_ANN = load_model('Final.h5')\n\n# Check accuracy\nfrom tensorflow.keras.utils import load_img, img_to_array\nimport numpy as np\nfilename = \"../input/11-money/5000/1.jpg\"\n\npredict = ['200','500','1000','2000','5000','10000','20000','50000','100000','200000','500000']\npredict = np.array(predict)\n\n\nimg = load_img(filename,target_size=(150,150))\nimg = img_to_array(img)\nimg = img.reshape(1,150,150,3)\nimg = img.astype('float32')\nimg = img/255\n\nresult = np.argmax(model_ANN.predict(img),axis=-1)\npredict[result]","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:10:51.761819Z","iopub.execute_input":"2022-05-20T06:10:51.762055Z","iopub.status.idle":"2022-05-20T06:10:52.162811Z","shell.execute_reply.started":"2022-05-20T06:10:51.762023Z","shell.execute_reply":"2022-05-20T06:10:52.162085Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Load 1 image\nimg = image.load_img(\"../input/11-money/5000/1.jpg\")\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:19:55.257198Z","iopub.execute_input":"2022-05-20T06:19:55.257887Z","iopub.status.idle":"2022-05-20T06:19:55.466631Z","shell.execute_reply.started":"2022-05-20T06:19:55.257851Z","shell.execute_reply":"2022-05-20T06:19:55.465998Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Results\nscore = model.evaluate(X_test,Y_test, verbose=0)\nprint(\"Loss = \", score[0])\nprint(\"accuracy = \", score[1])","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:10:56.999810Z","iopub.execute_input":"2022-05-20T06:10:57.000531Z","iopub.status.idle":"2022-05-20T06:10:57.515684Z","shell.execute_reply.started":"2022-05-20T06:10:57.000491Z","shell.execute_reply":"2022-05-20T06:10:57.514508Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Draw plot\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train','Validation'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:11:14.095150Z","iopub.execute_input":"2022-05-20T06:11:14.095449Z","iopub.status.idle":"2022-05-20T06:11:14.320286Z","shell.execute_reply.started":"2022-05-20T06:11:14.095421Z","shell.execute_reply":"2022-05-20T06:11:14.319614Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}