{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import Libraries\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nimport os\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras import layers\n# Gọi các thư viện cần thiết \nimport pandas as pd # Xu lý bảng\nimport seaborn as sns # Vẽ biểu đồ thị của dữ liệu\nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import StandardScaler # Xử lý chuẩn hóa dữ liệu\nfrom sklearn.model_selection import train_test_split # Chia dữ liệu ra làm 2 phần\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization, LSTM    # LSTM  biên dạng ANN, BatchNormalization: cho nhỏ lại\nfrom keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical # Sử dung để làm nổi đối tượng cần phân loại\nfrom keras import callbacks \nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score # Để đo lường\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nfrom tensorflow.keras.preprocessing import image\nfrom keras.layers import Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport cv2\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom keras import callbacks\nimport keras\nfrom keras.layers import Dense # fully connected\nfrom keras.datasets import boston_housing\nfrom tensorflow.keras.optimizers import RMSprop # toi uu\nfrom keras.callbacks import EarlyStopping # dung lai ngay lap tuc\nfrom sklearn.preprocessing import scale # xu li du lieu\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T05:59:42.064845Z","iopub.execute_input":"2022-05-20T05:59:42.065292Z","iopub.status.idle":"2022-05-20T05:59:48.539195Z","shell.execute_reply.started":"2022-05-20T05:59:42.065198Z","shell.execute_reply":"2022-05-20T05:59:48.538417Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load 1 image\nimg = image.load_img(\"../input/10-fruits/10 fruit/apple/Image_10.jpg\")\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T05:59:48.540786Z","iopub.execute_input":"2022-05-20T05:59:48.541062Z","iopub.status.idle":"2022-05-20T05:59:48.950242Z","shell.execute_reply.started":"2022-05-20T05:59:48.541028Z","shell.execute_reply":"2022-05-20T05:59:48.949475Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Reshape data\nimport glob\napple = glob.glob('../input/10-fruits/10 fruit/apple/*.*')\nbanana = glob.glob('../input/10-fruits/10 fruit/banana/*.*')\ncarrot = glob.glob('../input/10-fruits/10 fruit/carrot/*.*')\ncorn = glob.glob('../input/10-fruits/10 fruit/corn/*.*')\ncucumber = glob.glob('../input/10-fruits/10 fruit/cucumber/*.*')\ngarlic = glob.glob('../input/10-fruits/10 fruit/garlic/*.*')\ngrapes = glob.glob('../input/10-fruits/10 fruit/grapes/*.*')\nlemon = glob.glob('../input/10-fruits/10 fruit/lemon/*.*')\nmango = glob.glob('../input/10-fruits/10 fruit/mango/*.*')\norange = glob.glob('../input/10-fruits/10 fruit/orange/*.*')\n\ndata = []\nlabels = []\n\nfor i in apple:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(0)\nfor i in banana:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(1)\nfor i in carrot:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(2)\nfor i in corn:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(3)\n\nfor i in cucumber:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(4)\nfor i in garlic:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(5)\nfor i in grapes:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(6)\nfor i in lemon:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(7)\nfor i in mango:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(8)\nfor i in orange:   \n    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n    target_size= (150,150))\n    image=np.array(image)\n    data.append(image)\n    labels.append(9)\n\ndata = np.array(data)\nlabels = np.array(labels)\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size=0.2,\n                                                random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T05:59:48.951286Z","iopub.execute_input":"2022-05-20T05:59:48.951517Z","iopub.status.idle":"2022-05-20T06:00:34.755831Z","shell.execute_reply.started":"2022-05-20T05:59:48.951483Z","shell.execute_reply":"2022-05-20T06:00:34.755095Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape,Y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:00:34.757695Z","iopub.execute_input":"2022-05-20T06:00:34.757967Z","iopub.status.idle":"2022-05-20T06:00:34.763615Z","shell.execute_reply.started":"2022-05-20T06:00:34.757933Z","shell.execute_reply":"2022-05-20T06:00:34.762880Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reshape((X_train.shape[0],150,150,3)).astype('float32')/255\nX_test = X_test.reshape((X_test.shape[0],150,150,3)).astype('float32')/255\n\nY_train = to_categorical(Y_train,10)\nY_test = to_categorical(Y_test,10)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:00:34.764869Z","iopub.execute_input":"2022-05-20T06:00:34.765343Z","iopub.status.idle":"2022-05-20T06:00:34.841462Z","shell.execute_reply.started":"2022-05-20T06:00:34.765305Z","shell.execute_reply":"2022-05-20T06:00:34.840662Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:00:34.842762Z","iopub.execute_input":"2022-05-20T06:00:34.843024Z","iopub.status.idle":"2022-05-20T06:00:34.856622Z","shell.execute_reply.started":"2022-05-20T06:00:34.842975Z","shell.execute_reply":"2022-05-20T06:00:34.855745Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(Y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:00:34.858399Z","iopub.execute_input":"2022-05-20T06:00:34.858642Z","iopub.status.idle":"2022-05-20T06:00:34.864461Z","shell.execute_reply.started":"2022-05-20T06:00:34.858609Z","shell.execute_reply":"2022-05-20T06:00:34.863653Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Preprocessing\ntrain = ImageDataGenerator(rescale=1/255)\nimage_generator = ImageDataGenerator(rescale=1/255, validation_split=0.2)    \n\ntrain_dataset = image_generator.flow_from_directory(batch_size=32,\n                                                 directory=\"../input/10-fruits/10 fruit/\",\n                                                 shuffle=True,\n                                                 target_size=(150, 150), \n                                                 subset=\"training\",\n                                                 class_mode='categorical')\n\nvalidation_dataset = image_generator.flow_from_directory(batch_size=32,\n                                                 directory=\"../input/10-fruits/10 fruit/\",\n                                                 shuffle=True,\n                                                 target_size=(150, 150), \n                                                 subset=\"validation\",\n                                                 class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:00:34.865740Z","iopub.execute_input":"2022-05-20T06:00:34.866501Z","iopub.status.idle":"2022-05-20T06:00:35.082521Z","shell.execute_reply.started":"2022-05-20T06:00:34.866464Z","shell.execute_reply":"2022-05-20T06:00:35.081760Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_dataset.class_indices","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:00:35.085175Z","iopub.execute_input":"2022-05-20T06:00:35.085662Z","iopub.status.idle":"2022-05-20T06:00:35.093572Z","shell.execute_reply.started":"2022-05-20T06:00:35.085618Z","shell.execute_reply":"2022-05-20T06:00:35.092804Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Create model\nfrom keras.layers import Conv2D, MaxPooling2D\nmodel = Sequential()\nmodel.add(Conv2D(32,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(150,150,3)))\nmodel.add(Conv2D(32,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same'))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(64,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same')) # 64 lan tich chap\nmodel.add(Conv2D(64,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same'))\nmodel.add(MaxPooling2D(2,2))\n\nmodel.add(Conv2D(128,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same')) # 128 lan tich chap\nmodel.add(Conv2D(128,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same'))\nmodel.add(MaxPooling2D(2,2))\n\n# model.add(Conv2D(256,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same')) # 256 lan tich chap\n# model.add(Conv2D(256,(3,3), activation='relu',kernel_initializer='he_uniform',padding='same'))\n# model.add(MaxPooling2D(2,2))\n\n\nfrom keras.layers import Dense, Activation, Flatten\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu', kernel_initializer='he_uniform'))\nmodel.add(Dense(10))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:01:07.957634Z","iopub.status.idle":"2022-05-20T06:01:07.958208Z","shell.execute_reply.started":"2022-05-20T06:01:07.957956Z","shell.execute_reply":"2022-05-20T06:01:07.957997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.compile(loss='mse',optimizer=RMSprop(),metrics=['accuracy'])\nhistory = model.fit(X_train, Y_train, epochs =50, batch_size =128,validation_data=(X_test,Y_test) , verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:01:08.890306Z","iopub.execute_input":"2022-05-20T06:01:08.891124Z","iopub.status.idle":"2022-05-20T06:01:51.146637Z","shell.execute_reply.started":"2022-05-20T06:01:08.891085Z","shell.execute_reply":"2022-05-20T06:01:51.145864Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Compile model\nmodel.compile(\n    optimizer='rmsprop',\n#     loss='categorical_crossentropy',\n    loss='mse',\n    metrics=[\"accuracy\"])\n# Training\nhistory = model.fit(X_train,Y_train, epochs=10, batch_size=64,verbose=1, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:00:55.837848Z","iopub.execute_input":"2022-05-20T06:00:55.838062Z","iopub.status.idle":"2022-05-20T06:01:07.112462Z","shell.execute_reply.started":"2022-05-20T06:00:55.838036Z","shell.execute_reply":"2022-05-20T06:01:07.111657Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Save model\nfrom tensorflow.keras.models import load_model\nmodel.save('Final.h5')\nmodel_ANN = load_model('Final.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:01:07.114209Z","iopub.execute_input":"2022-05-20T06:01:07.115083Z","iopub.status.idle":"2022-05-20T06:01:07.381866Z","shell.execute_reply.started":"2022-05-20T06:01:07.115036Z","shell.execute_reply":"2022-05-20T06:01:07.381118Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Check accuracy\nfrom tensorflow.keras.utils import load_img, img_to_array\nimport numpy as np\nfilename = \"../input/fruit-and-vegetable-image-recognition/test/orange/Image_10.png\"\n\npredict = ['apple','banana','carrot','corn','cucumber','garlic','grapes','lemon','mango','orange']\npredict = np.array(predict)\n\n\nimg = load_img(filename,target_size=(150,150))\nimg = img_to_array(img)\nimg = img.reshape(1,150,150,3)\nimg = img.astype('float32')\nimg = img/255\n\nresult = np.argmax(model_ANN.predict(img),axis=-1)\npredict[result]","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:01:07.383040Z","iopub.execute_input":"2022-05-20T06:01:07.383303Z","iopub.status.idle":"2022-05-20T06:01:07.665615Z","shell.execute_reply.started":"2022-05-20T06:01:07.383259Z","shell.execute_reply":"2022-05-20T06:01:07.664909Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Load 1 image\nimg = image.load_img(\"../input/fruit-and-vegetable-image-recognition/test/orange/Image_10.png\")\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:01:07.667023Z","iopub.execute_input":"2022-05-20T06:01:07.667275Z","iopub.status.idle":"2022-05-20T06:01:07.954615Z","shell.execute_reply.started":"2022-05-20T06:01:07.667241Z","shell.execute_reply":"2022-05-20T06:01:07.953530Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Results\nscore = model.evaluate(X_test,Y_test, verbose=0)\nprint(\"Loss = \", score[0])\nprint(\"accuracy = \", score[1])","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:02:38.833518Z","iopub.execute_input":"2022-05-20T06:02:38.833783Z","iopub.status.idle":"2022-05-20T06:02:39.421481Z","shell.execute_reply.started":"2022-05-20T06:02:38.833754Z","shell.execute_reply":"2022-05-20T06:02:39.420668Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Draw plot\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['train','Validation'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T06:02:51.595406Z","iopub.execute_input":"2022-05-20T06:02:51.595671Z","iopub.status.idle":"2022-05-20T06:02:51.785467Z","shell.execute_reply.started":"2022-05-20T06:02:51.595641Z","shell.execute_reply":"2022-05-20T06:02:51.784761Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}